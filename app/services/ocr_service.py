from __future__ import annotations

import time
import re
import io
from typing import List, Optional, Dict, Any, Tuple
from pathlib import Path

import PyPDF2
from pdf2image import convert_from_bytes
import pytesseract
from PIL import Image
import cv2
import numpy as np

from app.schemas.ocr import ExtractedText, ResumeData


class OCRService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF —Ä–µ–∑—é–º–µ"""
    
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Tesseract
        self.tesseract_config = '--oem 3 --psm 6'
        
        # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        self.patterns = {
            'name': [
                r'^([–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)?)',
                r'–§–ò–û[:\s]+([–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+)',
                r'–ò–º—è[:\s]+([–ê-–Ø–Å][–∞-—è—ë]+)',
            ],
            'email': [
                r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            ],
            'phone': [
                r'\+?[78][-\(]?\d{3}[-\)]?\d{3}[-]?\d{2}[-]?\d{2}',
                r'\b\d{3}[-]?\d{3}[-]?\d{2}[-]?\d{2}\b',
            ],
            'experience': [
                r'–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–°—Ç–∞–∂[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–†–∞–±–æ—Ç–∞–ª[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
            ],
            'education': [
                r'–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–ò–Ω—Å—Ç–∏—Ç—É—Ç[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
            ],
            'skills': [
                r'–ù–∞–≤—ã–∫–∏[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–ó–Ω–∞—é[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
            ],
            'languages': [
                r'–Ø–∑—ã–∫–∏[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–ê–Ω–≥–ª–∏–π—Å–∫–∏–π[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
                r'–ò–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã–µ —è–∑—ã–∫–∏[:\s]+(.+?)(?=\n\n|\n[A-Z–ê-–Ø]|$)',
            ],
        }
    
    async def process_pdf(self, pdf_bytes: bytes, filename: str) -> Tuple[List[ExtractedText], ResumeData]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF"""
        start_time = time.time()
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ PDF
            extracted_text = await self._extract_text_from_pdf(pdf_bytes)
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ
            resume_data = await self._extract_resume_data(extracted_text)
            
            processing_time = time.time() - start_time
            print(f"‚úÖ PDF –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {processing_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            return extracted_text, resume_data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {e}")
            raise
    
    async def _extract_text_from_pdf(self, pdf_bytes: bytes) -> List[ExtractedText]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Å –ø–æ–º–æ—â—å—é OCR"""
        extracted_text = []
        
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –Ω–∞–ø—Ä—è–º—É—é –∏–∑ PDF
            pdf_text = await self._extract_pdf_text(pdf_bytes)
            
            if pdf_text and any(len(text.strip()) > 50 for text in pdf_text):
                # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∏–∑–≤–ª–µ—á–µ–Ω —É—Å–ø–µ—à–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                for i, text in enumerate(pdf_text):
                    if text.strip():
                        extracted_text.append(ExtractedText(
                            page_number=i + 1,
                            text=text.strip(),
                            confidence=1.0,  # PDF —Ç–µ–∫—Å—Ç –∏–º–µ–µ—Ç 100% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                            bounding_boxes=None
                        ))
                print(f"üìÑ –ò–∑–≤–ª–µ—á–µ–Ω —Ç–µ–∫—Å—Ç –∏–∑ {len(extracted_text)} —Å—Ç—Ä–∞–Ω–∏—Ü PDF")
                return extracted_text
            
            # –ï—Å–ª–∏ PDF —Ç–µ–∫—Å—Ç –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º OCR
            print("üîç –ò—Å–ø–æ–ª—å–∑—É–µ–º OCR –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞...")
            extracted_text = await self._ocr_extraction(pdf_bytes)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
            raise
        
        return extracted_text
    
    async def _extract_pdf_text(self, pdf_bytes: bytes) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ PDF"""
        try:
            pdf_file = io.BytesIO(pdf_bytes)
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            
            texts = []
            for page in pdf_reader.pages:
                text = page.extract_text()
                texts.append(text)
            
            return texts
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF: {e}")
            return []
    
    async def _ocr_extraction(self, pdf_bytes: bytes) -> List[ExtractedText]:
        """OCR –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
        extracted_text = []
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            images = convert_from_bytes(pdf_bytes, dpi=300)
            print(f"üñºÔ∏è PDF –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            
            for i, image in enumerate(images):
                print(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {i + 1}/{len(images)}...")
                
                # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                processed_image = await self._preprocess_image(image)
                
                # OCR –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
                text, confidence, boxes = await self._extract_text_from_image(processed_image)
                
                extracted_text.append(ExtractedText(
                    page_number=i + 1,
                    text=text,
                    confidence=confidence,
                    bounding_boxes=boxes
                ))
                
                print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {i + 1}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            raise
        
        return extracted_text
    
    async def _preprocess_image(self, image: Image.Image) -> np.ndarray:
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è OCR"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
            img_array = np.array(image)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if len(img_array.shape) == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # –£–±–∏—Ä–∞–µ–º —à—É–º
            denoised = cv2.fastNlMeansDenoising(enhanced)
            
            # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
            _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            return binary
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            return np.array(image)
    
    async def _extract_text_from_image(self, image: np.ndarray) -> Tuple[str, float, List[Dict[str, Any]]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Tesseract"""
        try:
            # OCR –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
            ocr_data = pytesseract.image_to_data(
                image, 
                config=self.tesseract_config,
                output_type=pytesseract.Output.DICT
            )
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            text_parts = []
            bounding_boxes = []
            
            for i in range(len(ocr_data['text'])):
                if int(ocr_data['conf'][i]) > 30:  # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    text = ocr_data['text'][i].strip()
                    if text:
                        text_parts.append(text)
                        
                        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –±–ª–æ–∫–∞
                        box = {
                            'x': ocr_data['left'][i],
                            'y': ocr_data['top'][i],
                            'width': ocr_data['width'][i],
                            'height': ocr_data['height'][i],
                            'confidence': int(ocr_data['conf'][i]) / 100.0
                        }
                        bounding_boxes.append(box)
            
            full_text = ' '.join(text_parts)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            avg_confidence = np.mean([box['confidence'] for box in bounding_boxes]) if bounding_boxes else 0.0
            
            return full_text, avg_confidence, bounding_boxes
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ OCR –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            return "", 0.0, []
    
    async def _extract_resume_data(self, extracted_text: List[ExtractedText]) -> ResumeData:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–µ–∑—é–º–µ"""
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
            full_text = '\n'.join([et.text for et in extracted_text])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
            extracted_data = {}
            
            for field, patterns in self.patterns.items():
                for pattern in patterns:
                    match = re.search(pattern, full_text, re.IGNORECASE | re.MULTILINE)
                    if match:
                        if field == 'name':
                            extracted_data[field] = match.group(1).strip()
                        elif field == 'email':
                            extracted_data[field] = match.group(0).strip()
                        elif field == 'phone':
                            extracted_data[field] = match.group(0).strip()
                        else:
                            extracted_data[field] = match.group(1).strip() if match.groups() else match.group(0).strip()
                        break
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–≤—ã–∫–æ–≤
            skills = self._extract_skills_from_text(full_text)
            if skills:
                extracted_data['skills'] = skills
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —è–∑—ã–∫–æ–≤
            languages = self._extract_languages_from_text(full_text)
            if languages:
                extracted_data['languages'] = languages
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç ResumeData
            resume_data = ResumeData(
                name=extracted_data.get('name'),
                email=extracted_data.get('email'),
                phone=extracted_data.get('phone'),
                experience=extracted_data.get('experience'),
                education=extracted_data.get('education'),
                skills=extracted_data.get('skills', []),
                languages=extracted_data.get('languages', []),
                summary=self._extract_summary(full_text),
                raw_text=full_text
            )
            
            print(f"üìã –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {', '.join([k for k, v in extracted_data.items() if v])}")
            
            return resume_data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –æ–±—ä–µ–∫—Ç —Å —Å—ã—Ä—ã–º —Ç–µ–∫—Å—Ç–æ–º
            full_text = '\n'.join([et.text for et in extracted_text])
            return ResumeData(raw_text=full_text)
    
    def _extract_skills_from_text(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        skills = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –Ω–∞–≤—ã–∫–æ–≤
        skill_patterns = [
            r'Python', r'Java', r'JavaScript', r'React', r'Angular', r'Vue',
            r'Node\.js', r'Django', r'Flask', r'FastAPI', r'PostgreSQL', r'MySQL',
            r'MongoDB', r'Redis', r'Docker', r'Kubernetes', r'Git', r'Linux',
            r'SQL', r'HTML', r'CSS', r'TypeScript', r'C\+\+', r'C#', r'Go',
            r'Rust', r'PHP', r'Ruby', r'Swift', r'Kotlin', r'Scala'
        ]
        
        for pattern in skill_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                skills.append(pattern)
        
        return list(set(skills))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    def _extract_languages_from_text(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        languages = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —è–∑—ã–∫–æ–≤
        language_patterns = [
            r'–ê–Ω–≥–ª–∏–π—Å–∫–∏–π[:\s]+([A-Za-z]+)', r'English[:\s]+([A-Za-z]+)',
            r'–ù–µ–º–µ—Ü–∫–∏–π[:\s]+([A-Za-z]+)', r'German[:\s]+([A-Za-z]+)',
            r'–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π[:\s]+([A-Za-z]+)', r'French[:\s]+([A-Za-z]+)',
            r'–ò—Å–ø–∞–Ω—Å–∫–∏–π[:\s]+([A-Za-z]+)', r'Spanish[:\s]+([A-Za-z]+)',
            r'–ö–∏—Ç–∞–π—Å–∫–∏–π[:\s]+([A-Za-z]+)', r'Chinese[:\s]+([A-Za-z]+)',
        ]
        
        for pattern in language_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                languages.append(match.group(1))
        
        return list(set(languages))
    
    def _extract_summary(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è"""
        # –ò—â–µ–º –ø–µ—Ä–≤—ã–µ 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', text)
        summary_sentences = [s.strip() for s in sentences[:3] if len(s.strip()) > 20]
        
        if summary_sentences:
            return '. '.join(summary_sentences) + '.'
        return None
